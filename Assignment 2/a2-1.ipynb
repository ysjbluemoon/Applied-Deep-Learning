{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "a2-1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtqfC-BqUWK4",
        "colab_type": "text"
      },
      "source": [
        "# A2: Image classification in the brower\n",
        "\n",
        "In this assignment, you will gain real-world experience with image classification on small datasets - a common scenario in practice. There are three parts.\n",
        "\n",
        "1. First, you will train a model on a small existing dataset.\n",
        "\n",
        "2. Next,  you will collect a small dataset yourself. Of course, in practice there isn’t often a dataset available for tasks you care about, so it’s valuable to get a feel for this process. You will train a small model from scratch, then use data augmentation to improve accuracy.\n",
        "\n",
        "3. Finally, you will deploy your model from part two in a webpage using TensorFlow.js. A user will be able to upload a photo, and your model will classify it.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Please complete this notebook by searching for **\"TODO\"**.\n",
        "\n",
        "## Submission instructions\n",
        "\n",
        "Please submit this assignment on CourseWorks by uploading a Jupyter notebook that includes saved output. If you are working in Colab, you can prepare your notebook for submission by ensuring that runs end-to-end, then saving and downloading it:\n",
        "\n",
        "1. ```Runtime -> Restart and run all```\n",
        "1. ```File -> Save```\n",
        "1. ```File -> Download.ipynb```\n",
        "\n",
        "Note: you will need to include a URL to your webpage for part 3, see the final TODO at the bottom of this notebook.\n",
        "\n",
        "## Setup instructions\n",
        "1. If you are running this notebook in Colab, make sure a GPU is enabled (```Edit -> Notebook settings -> Hardware accelerator```).\n",
        "\n",
        "2. Create a GitHub Pages repo by following the instructions at https://pages.github.com/. You may use this to host your webpage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TmzbQJkCeXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x # enable TF 2.x in Colab\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oLmcZORRh7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5UDOaU1AzVr",
        "colab_type": "text"
      },
      "source": [
        "## 1a) Flowers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ3Hv7NGRTdy",
        "colab_type": "text"
      },
      "source": [
        "In this part of the assignment, you will train a model on a small existing dataset (flowers)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks38bmgRA-xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import IPython.display as display\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import time\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = 192\n",
        "SHUFFLE_SIZE = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Rc1LdwCVFb4",
        "colab_type": "text"
      },
      "source": [
        "### Download the flowers dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRYep9qMqG15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pathlib\n",
        "data_root_orig = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "                                         fname='flower_photos', untar=True)\n",
        "data_root = pathlib.Path(data_root_orig)\n",
        "print(data_root)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WziL5x5QJUYk",
        "colab_type": "text"
      },
      "source": [
        "### Write an input pipeline from scratch\n",
        "There are several ways to load images in TensorFlow. Later in this assignment, you'll use the [Keras preprocessing utilities](https://keras.io/preprocessing/image/). For starters, though, you'll write your own using ```tf.data```, based on this [tutorial](https://www.tensorflow.org/beta/tutorials/load_data/images). This is valuable to do once (just so you can see how the nuts and bolts work) before using the higher level utils. A bunch of the code is written for you, there are only a couple of TODOs. Follow along, though, and try to understand each piece.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsLuAd_9BOpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_image_paths = list(data_root.glob('*/*'))\n",
        "all_image_paths = [str(path) for path in all_image_paths]\n",
        "random.shuffle(all_image_paths)\n",
        "\n",
        "image_count = len(all_image_paths)\n",
        "image_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViQ3n2MLBO49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_image_paths[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPxnpUSEVrZb",
        "colab_type": "text"
      },
      "source": [
        "### Get to know your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6UzHIm9CJvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for n in range(3):\n",
        "  image_path = random.choice(all_image_paths)\n",
        "  display.display(display.Image(image_path))\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GN3o_6PWRol",
        "colab_type": "text"
      },
      "source": [
        "### Classes are given by directory names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcHJPTI2BUFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "label_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prA5LRsL-kAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
        "label_to_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLedPtLeBo3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
        "                    for path in all_image_paths]\n",
        "\n",
        "print(\"First 10 labels indices: \", all_labels[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liCVsOmMAg0h",
        "colab_type": "text"
      },
      "source": [
        "### Create a train/test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUWoRvziAjNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(all_image_paths, all_labels)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWclr76cWY6d",
        "colab_type": "text"
      },
      "source": [
        "### Display a few images and their labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H88pb_WZCQ2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for n in range(3):\n",
        "  i = random.randint(0,len(train_paths))\n",
        "  image_path = train_paths[i]\n",
        "  print(label_names[train_labels[i]])\n",
        "  display.display(display.Image(image_path))\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X-BkNVMWhFS",
        "colab_type": "text"
      },
      "source": [
        "### Begin using TensorFlow ops to read and decode the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC1hfUW8Bt__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_raw = tf.io.read_file(train_paths[0])\n",
        "print(repr(img_raw)[:100]+\"...\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNhUSCKPBxo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_tensor = tf.image.decode_image(img_raw)\n",
        "print(img_tensor.shape)\n",
        "print(img_tensor.dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2c_Cg3xB0sc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_final = tf.image.resize(img_tensor, [IMG_SIZE, IMG_SIZE])\n",
        "img_final = img_final / 255.0 # normalize pixel values\n",
        "print(img_final.shape)\n",
        "print(img_final.numpy().min())\n",
        "print(img_final.numpy().max())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfRp-wOQR9-9",
        "colab_type": "text"
      },
      "source": [
        "### Wrap those in a function\n",
        "Tip: pay careful attention to the preprocessing. When you deploy models in the browser, you will need to ensure that images are preprocessed identically in JavaScript as they are in Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5XfV-IoB33F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_and_preprocess_image(path):\n",
        "  img = tf.io.read_file(path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "  img /= 255.0  # normalize to [0,1] range\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0iUW3KZB66L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show(img, label):\n",
        "  plt.imshow(img)\n",
        "  plt.title(label)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  print()\n",
        "\n",
        "img_path = train_paths[0]\n",
        "img = load_and_preprocess_image(img_path)\n",
        "label = label_names[train_labels[0]]\n",
        "show(img, label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5rBhm42YFC9",
        "colab_type": "text"
      },
      "source": [
        "### Build an input pipeline to return images and labels\n",
        "I realize this is complicated. The problem we're trying to solve using tf.data is performance (we want our preprocessing to run in C, but to write our code in Python). There are a bunch of advanced tricks you can do with tf.data as well (e.g. prefetching images to the GPU).\n",
        "\n",
        "Note: although your *peak* performance can be higher, it's also very easy to make mistakes and end up with code that's super slow. Always benchmark your input pipelines before using them (shown in a bit). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3vFPZ15B8vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a dataset that returns image paths\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(train_paths)\n",
        "for n, img_path in enumerate(path_ds.take(4)):\n",
        "  print(n, img_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBKMDNUaI1VW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a dataset that returns images (loaded off disk, decoded, and preprocessed)\n",
        "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "for n, image in enumerate(image_ds.take(4)):\n",
        "  print(n, image.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73M1D4kcJKA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a dataset that returns labels\n",
        "label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(train_labels, tf.int64))\n",
        "for label in label_ds.take(4):\n",
        "  print(label_names[label.numpy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz4G6ec5JN14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a dataset that returns images and labels\n",
        "image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
        "print(image_label_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOxThxj5KtgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for img, label in image_label_ds.take(2):\n",
        "  print(img.shape, label_names[label.numpy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YQxyvQdYkwS",
        "colab_type": "text"
      },
      "source": [
        "### Batch and shuffle\n",
        "Why do we need to specify a shuffle_size parameter? tf.data works with streams (it doesn't know their length). To shuffle items, we maintain an in-memory buffer of this size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRC09hBCYmNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = image_label_ds.shuffle(SHUFFLE_SIZE)\n",
        "ds = ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "for img, label in ds.take(2):\n",
        "  print(img.shape, label.shape) # notice it's returning batches of data now"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTUXFRceYvgB",
        "colab_type": "text"
      },
      "source": [
        "At this point, you could use the dataset above to train a model with ```model.fit(ds)``` but first, let's improve performance. As written, the dataset will load each image off disk, one at a time (super slow). Instead, we want to cache them in memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "topeFvIZYKkM",
        "colab_type": "text"
      },
      "source": [
        "### Improve performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiRagWwcLNZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A benchmark utility to time how long it takes\n",
        "# to iterate once over the entire dataset\n",
        "def time_one_epoch(ds):\n",
        "  start = time.time()\n",
        "  batches = 0\n",
        "  for i,(images,labels) in enumerate(ds):\n",
        "    batches += 1\n",
        "    if i % 10 == 0:\n",
        "      print('.', end='')\n",
        "  print()\n",
        "  end = time.time()\n",
        "  duration = end-start\n",
        "  print(\"Read {} batches\".format(batches))\n",
        "  print(\"{:0.2f} Batches/s\".format(batches/duration))\n",
        "  print(\"{:0.2f} Images/s\".format(BATCH_SIZE*batches/duration))\n",
        "  print(\"Total time: {}s\".format(duration))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl39fR2WNM4t",
        "colab_type": "text"
      },
      "source": [
        "### Use in-memory caching\n",
        "This is a small dataset, so let's keep it in memory. The first time we iterate over this dataset, images will be loaded off disk, then cached. The first iteration will be quite slow, and subsequent ones will be faster. Let's show that. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzs0lpOxKf1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = image_label_ds.cache() # cache data in mempry\n",
        "ds = ds.shuffle(SHUFFLE_SIZE)\n",
        "ds = ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAVRB2J6NjQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_one_epoch(ds) # this will be slow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIZjksy8NS_J",
        "colab_type": "text"
      },
      "source": [
        "Now that the cache is built, iteration will be much faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBD-VrIELSdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_one_epoch(ds) # this will be fast"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR511DHJN_8A",
        "colab_type": "text"
      },
      "source": [
        "If the dataset did not fit into memory, you could use a cache file on disk, like this:\n",
        "\n",
        "```\n",
        "ds = image_label_ds.cache(filename='./cache.tf-data')\n",
        "ds = ds.shuffle(buffer_size=BUFFER_SIZE)\n",
        "ds = ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "```\n",
        "\n",
        "This can be useful to perform expensive preprocessing only once, and/or to improve file I/O (TF saves the cache file in an efficient format - it can be faster to read one large file than a bunch of small ones)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp8BS9PKBs6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# here's our final training dataset\n",
        "train_ds = image_label_ds.cache()\n",
        "train_ds = train_ds.shuffle(SHUFFLE_SIZE)\n",
        "train_ds = train_ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# let's make a test dataset as well\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(test_paths)\n",
        "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(test_labels, tf.int64))\n",
        "image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
        "test_ds = image_label_ds.cache().batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CWKa6YmaAYJ",
        "colab_type": "text"
      },
      "source": [
        "### Finally, we have a fast pipeline ready to go, written from scratch\n",
        "Now, let's define a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3COLSNc89pRl",
        "colab_type": "text"
      },
      "source": [
        "## 1b) Create a simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GS41XUM98QO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', \n",
        "                        input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "model.add(layers.MaxPooling2D())\n",
        "### TODO: your code here\n",
        "# Add another pair of Conv2d and MaxPoolin2dD layers\n",
        "# As the depth of the network increases, the images\n",
        "# become smaller, and you can afford to use more \n",
        "# filters in each layer\n",
        "###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUxfKSDE99Oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw7diGWD9q4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(5, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLm40HMqS_Wh",
        "colab_type": "text"
      },
      "source": [
        "### Tip: pay attention to the size of the model\n",
        "Later, when you export a model to run in the webpage, you will want a small one (in terms of the number of parameters) that downloads quickly. Notice how much more efficient the convolutional layers are than the dense ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX7TsjJZU8OL",
        "colab_type": "text"
      },
      "source": [
        "### Tip: pay attention to exactly how your images are preprocessed\n",
        "Later, when you run your model in a browser, you'll need to preprocess images in Javascript in exactly the same way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrYOXpLc90wt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV9mFvExCvZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyJjOEfd94cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I realize we're using the test dataset (that's fine for this assignment)\n",
        "model.fit(train_ds, validation_data=test_ds, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqSkDOWiatnY",
        "colab_type": "text"
      },
      "source": [
        "### Make predictions on a single image\n",
        "Tip: models are implemented to make predictions on batches of images for efficiency. This means that to make a prediction on a single image, you'll need to first wrap it in a batch. The syntax can feel a little unusual at first, but gets easier with time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtiTdJm3-yrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load an image off disk\n",
        "img_index = 0\n",
        "img = load_and_preprocess_image(train_paths[img_index])\n",
        "\n",
        "print(img.shape) # before\n",
        "\n",
        "#########\n",
        "## TODO: your code here\n",
        "## use tf.expand_dims to create an empty batch dimension\n",
        "## the starting image shape is (192, 192, 3)\n",
        "## you want it to be (1, 192, 192, 3)\n",
        "## that's read as \"a batch of 1 image, with 192 rows, 192 cols, \n",
        "## and 3 color channels\"\n",
        "#########\n",
        "im_batch = None # YOUR CODE HERE, use tf.expand_dims\n",
        "\n",
        "print(im_batch.shape) # after\n",
        "\n",
        "# make predictions\n",
        "batch_pred = model.predict(im_batch) # returns a list of predictions\n",
        "pred = batch_pred[0] \n",
        "\n",
        "print(\"Prediction\", label_names[tf.argmax(pred)])\n",
        "print(\"Actual\", label_names[train_labels[img_index]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDiBS04Q_rRL",
        "colab_type": "text"
      },
      "source": [
        "### TODO: Improve accuracy\n",
        "Write a new model that's more accurate than the baseline above (the baseline has only one Conv2D and MaxPooling2D layer). Produce plots of loss / accuracy as a function of epochs. Train your model without overfitting. For this assignment, it is not necessary to build a super accurate model - just experiment a bit and try to improve over the baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuuLJJszDAy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc3yX-amDMFG",
        "colab_type": "text"
      },
      "source": [
        "## 1c) Try to get your flowers model working in TensorFlow.js\n",
        "In the final part of the assignment, you'll export the model you build to recognize landmarks on Columbia's campus, and get it working in the browser. It's easiest to start by exporting your flowers model, and getting it working with TensorFlow.js (the starter code is build around your flowers model, so you can learn the mechanics before trying something more complex)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLVgG2eBDmu6",
        "colab_type": "text"
      },
      "source": [
        "### Save your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM20AUr4Doqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/my_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4ALIsEbLs07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -lha"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCSblyG1J42B",
        "colab_type": "text"
      },
      "source": [
        "### Download it to your local machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYwiPmqXJ5mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/my_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itHCUxY3DytP",
        "colab_type": "text"
      },
      "source": [
        "### Visit notebook #2 to convert it to TensorFlow.js format\n",
        "Follow the instructions there to prepare a webpage to run your flowers model in the browser. Once you have that working, continue with the rest of this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTU9vX0Kcawh",
        "colab_type": "text"
      },
      "source": [
        "## 1d) Transfer learning\n",
        "\n",
        "In this part of the assignment, you'll use transfer learning to take advantage of a large pretrained model. It is not necesary to deploy this part in the browser.\n",
        "\n",
        "\n",
        "References:\n",
        "* https://www.tensorflow.org/beta/tutorials/images/transfer_learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk4pYnFiXuKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TODO: your code here\n",
        "# Choose a pretrained model, and import the application\n",
        "# See https://keras.io/applications/ for a few choices\n",
        "# When you import the model, you will want to remove the \n",
        "# final dense layer that performs classification (include_top=False)\n",
        "# you will also want to import weights from ImageNet,\n",
        "# and you will want to specify the input shape to match your images. \n",
        "\n",
        "base_model = None # fix me. base_model = tf.keras.applications..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW9kjNblDRBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A hack to show you the output shape of the model\n",
        "for image_batch, label_batch in train_ds.take(1):\n",
        "   pass\n",
        "  \n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwxsas1j-JYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# do not update the pretrained weights during training\n",
        "# (we won't use finetuning here)\n",
        "base_model.trainable = False "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7JdYOWG-Lsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l0gBu3o-NLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(5, activation='softmax')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXQPRAsF-UWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build a new model reusing the pretrained base\n",
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  global_average_layer,\n",
        "  prediction_layer\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k_CFl0d-vg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3w5RPot-wMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_ds, validation_data=test_ds, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTHrHpf6da5d",
        "colab_type": "text"
      },
      "source": [
        "## 2a) Recognize landmarks on Columbia's campus\n",
        "\n",
        "In this part of the assignment, you will train a model to recognize landmarks (famous places, like the [Alma Mater sculpture](https://en.wikipedia.org/wiki/Alma_Mater_(New_York_sculpture), or Butler library) on Columbia’s campus. Instead of tf.data, you will gain experience with the higher level Keras utilties. You will also experiment with data augmentation to increase the effective size of your dataset.\n",
        "\n",
        "Starter code is not provided for this part of the assignment. You should base your work off the following Keras notebook, which works identically in TF2 (the only thing you'll need to change is the imports, an example of correct imports is given below).\n",
        "\n",
        "* https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.2-using-convnets-with-small-datasets.ipynb\n",
        "\n",
        "Here are steps you should complete.\n",
        "\n",
        "1. Collect a dataset of at least three landmarks. Your dataset should include at least 50 images of each landmark in train, and 50 in validation (using more images is fine). Randomly shuffle your data to create these splits. You do not need to use a separate test set in this assignment.\n",
        "\n",
        " You will need to upload your dataset to Colab in order to train a model. To do so, you can either upload it using the file browser (slow and tedious, you'll need to repeat that if your runtime is reset), or (better) you can upload your dataset to Google Drive, then mount your drive as a filesystem in Colab (View -> Table of contents -> Code snippets -> search for \"drive\"). This will enable you to access the contents of your drive with commands like `!ls /gdrive`. As a another option, you could upload your dataset to a cloud provider or your Columbia account, then download it similarly to flowers at the top of this notebook.\n",
        " \n",
        "1. Write a model to classify your data. Try to train a small model in terms of the number of parameters (you do not need to use transfer learning). \n",
        "\n",
        "1. Show predictions on several images.\n",
        "\n",
        "1. Use data augmentation, see if this helps to improve accuracy.\n",
        "\n",
        "1. Produce plots of accuracy / loss as a function of epochs. Determine the right place to stop training without overfitting.\n",
        "\n",
        "When you have a reasonably accurate model, proceed to the next step. There are no guidelines for accuracy, try to build something you feel works well, given the small amount of data you have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDfkcDbzHjsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example code showing the correct imports\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Example code:\n",
        "# You should use the keras preprocessing utilities here instead of tf.data\n",
        "# Here's an example of how to use them with the flowers dataset\n",
        "# You will need to add data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        data_root,\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        batch_size=32)\n",
        "\n",
        "for data_batch, labels_batch in train_generator:\n",
        "    print('data batch shape:', data_batch.shape)\n",
        "    print('labels batch shape:', labels_batch.shape)\n",
        "    break\n",
        "\n",
        "###\n",
        "# TODO: your code for 2a here.\n",
        "###\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHvhvaVdJAu8",
        "colab_type": "text"
      },
      "source": [
        "## 2b) Donate your dataset (optional)\n",
        "We will use the dataset collected by the class later in the semester.\n",
        "\n",
        "Requirements:\n",
        "\n",
        "* Please do not include any images with people in the foreground.\n",
        "* Only include images you have taken yourself and that you are comfortable sharing publicly under a [CCO](https://creativecommons.org/share-your-work/public-domain/cc0/) license (TLDR, public domain).\n",
        "\n",
        "Link to upload a zip is on CourseWorks. Your file should be in the same format as the flowers dataset (the directory names gives the label for each image).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUf9FFXa80E4",
        "colab_type": "text"
      },
      "source": [
        "## 3) Run your model in the browser\n",
        "Save and download your model, and head to notebook two again. After you've finished creating a webpage, upload it to GitHub pages or your Columbia account, list the URL here, and submit your assignment. You may not need to make many changes to the starter code, but pay attention to the preprocessing, number of output classes, image size, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCAdQMFo86Gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: http://your_webpage"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}