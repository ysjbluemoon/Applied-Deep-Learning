{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7-colab-to-webpage.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "e1cDMWdOjJ2r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook will help you go straight from training a model in Colab to deploying it in a webpage with TensorFlow.js (without having to leave the browser). This notebook uses code borrowed from here: https://github.com/tensorflow/tfjs-examples/tree/master/sentiment"
      ]
    },
    {
      "metadata": {
        "id": "pQmOHAcDnw7O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ft9uEY7UCH46",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs==1.0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "248xIjNGCRU0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. Configure this notebook to work with your GitHub account by populating these fields. Note: you may wish to create a separate, dummy GitHub account if you do not want to risk your personal data with this script.\n",
        "\n",
        "2. Before running the below cell, create a GitHub Pages repo by following the instructions at https://pages.github.com/"
      ]
    },
    {
      "metadata": {
        "id": "g4k9_Ke9CaOq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# your github username\n",
        "USER_NAME = \"UPDATE_ME\" \n",
        "\n",
        "# the email associated with your commits\n",
        "# (may not matter if you leave it as is)\n",
        "USER_EMAIL = \"foo@bar.com\" \n",
        "\n",
        "# create a token by visiting https://github.com/settings/tokens\n",
        "# choose public permissions\n",
        "# important: treat this token like a password (do not commit it)\n",
        "# or submit it w/ your HW.\n",
        "TOKEN = \"UPDATE_ME\" \n",
        "\n",
        "# for example, if your user_name is \"foo\", then this notebook will create\n",
        "# a site at \"https://foo.github.io/hw4/\"\n",
        "SITE_NAME = \"hw4\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dnPqmO8vDDwW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, run this cell to configure git."
      ]
    },
    {
      "metadata": {
        "id": "Q0IMoqVdCIb4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git config --global user.email {USER_NAME}\n",
        "!git config --global user.name  {USER_EMAIL}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XYfDxuMfDVas",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Clone your GitHub pages repo (see the lecture 8 slides for instructions on how to create one)."
      ]
    },
    {
      "metadata": {
        "id": "qRUyZiFqDUxt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "repo_path = USER_NAME + '.github.io'\n",
        "if not os.path.exists(os.path.join(os.getcwd(), repo_path)):\n",
        "  !git clone https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qu4OA27iDU0e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir(repo_path)\n",
        "!git pull"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KgISB_cAHPIs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a folder for your site."
      ]
    },
    {
      "metadata": {
        "id": "UAA6t4slF0nB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "project_path = os.path.join(os.getcwd(), SITE_NAME)\n",
        "if not os.path.exists(project_path): \n",
        "  os.mkdir(project_path)\n",
        "os.chdir(project_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DwYh8sXKHs3O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "These paths will be used by the converter script."
      ]
    },
    {
      "metadata": {
        "id": "ABggwdWMGe2h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY\n",
        "MODEL_DIR = os.path.join(project_path, \"model_js\")\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "  os.mkdir(MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TJpu2BkSUWe4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As an example, we will create and vectorize a few documents (check out https://gutenberg.org for a bunch of free e-books)."
      ]
    },
    {
      "metadata": {
        "id": "Pgm8y7fWHxOI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A few sentences from Alice in Wonderland\n",
        "ex1 = \"Alice was beginning to get very tired of sitting by her sister on the bank.\"\n",
        "ex2 = \"Once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it.\"\n",
        "\n",
        "# Dracula\n",
        "ex3 = \"Buda-Pesth seems a wonderful place.\"\n",
        "ex4 = \"Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning.\"\n",
        "\n",
        "# Illiad\n",
        "ex5 = \"Scepticism was as much the result of knowledge, as knowledge is of scepticism.\"\n",
        "ex6 = \"To be content with what we at present know, is, for the most part, to shut our ears against conviction.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CASpAIgJalTp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = [ex1, ex2, ex3, ex4, ex5, ex6]\n",
        "y_train = [0, 0, 1, 1, 2, 2] # Indicating which book each sentence is from"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CVfStwZCYBAq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tokenize the documents, create a word index (word -> number)."
      ]
    },
    {
      "metadata": {
        "id": "HOHTxREVQalF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_len = 20\n",
        "num_words = 1000\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# Fit the tokenizer on the training data\n",
        "t = Tokenizer(num_words=num_words)\n",
        "t.fit_on_texts(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mqyqHuLwWT-Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(t.word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "feIAyrrxYFoU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here's how we vectorize a document."
      ]
    },
    {
      "metadata": {
        "id": "Jfi7tJbHTwIc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vectorized = t.texts_to_sequences([ex1])\n",
        "print(vectorized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vUfL6MVhYHof",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Apply padding if necessary."
      ]
    },
    {
      "metadata": {
        "id": "rbghRbY5QaMV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded = pad_sequences(vectorized, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9xwd6ND_UIKk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(padded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C9NUXTTuYLZ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save the word index in metadata. Later, we'll use it to convert words typed in the browser to numbers for prediction (it's important the preprocessing is identical between Python and JS)."
      ]
    },
    {
      "metadata": {
        "id": "UpzusXHhULBr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metadata = {\n",
        "  'word_index': t.word_index,\n",
        "  'max_len': max_len,\n",
        "  'vocabulary_size': num_words,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l57eA3ApZGsC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define a model."
      ]
    },
    {
      "metadata": {
        "id": "oLQeTh3uVqtj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 8\n",
        "n_classes = 3\n",
        "epochs = 10\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(num_words, embedding_size, input_shape=(max_len,)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6VOtCRJiYWZZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Prepare some training data."
      ]
    },
    {
      "metadata": {
        "id": "-Q8Y1ZuZYYKC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = t.texts_to_sequences(x_train)\n",
        "x_train = pad_sequences(x_train, maxlen=max_len, padding='post')\n",
        "print(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VUWlD3jiX10c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y1YbPNWIenE5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Demo using the model to make predictions."
      ]
    },
    {
      "metadata": {
        "id": "KcmpKvKUY_hK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_example = \"Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning.\"\n",
        "x_test = t.texts_to_sequences([test_example])\n",
        "x_test = pad_sequences(x_test, maxlen=max_len, padding='post')\n",
        "print(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y9dsZSQnrqoU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preds = model.predict(x_test)\n",
        "print(preds)\n",
        "import numpy as np\n",
        "print(np.argmax(preds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G-Kuwvqcfptq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert the model"
      ]
    },
    {
      "metadata": {
        "id": "nyo2Q_ehe2RT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "metadata_json_path = os.path.join(MODEL_DIR, 'metadata.json')\n",
        "json.dump(metadata, open(metadata_json_path, 'wt'))\n",
        "tfjs.converters.save_keras_model(model, MODEL_DIR)\n",
        "print('\\nSaved model artifcats in directory: %s' % MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z609mw1aj-RJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Write an index.html and an index.js file configured to load our model."
      ]
    },
    {
      "metadata": {
        "id": "IoFAxt8nj9fp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index_html = \"\"\"\n",
        "<!doctype html>\n",
        "\n",
        "<body>\n",
        "  <style>\n",
        "    #textfield {\n",
        "      font-size: 120%;\n",
        "      width: 60%;\n",
        "      height: 200px;\n",
        "    }\n",
        "  </style>\n",
        "  <h1>\n",
        "    Title\n",
        "  </h1>\n",
        "  <hr>\n",
        "  <div class=\"create-model\">\n",
        "    <button id=\"load-model\" style=\"display:none\">Load model</button>\n",
        "  </div>\n",
        "  <div>\n",
        "    <div>\n",
        "      <span>Vocabulary size: </span>\n",
        "      <span id=\"vocabularySize\"></span>\n",
        "    </div>\n",
        "    <div>\n",
        "      <span>Max length: </span>\n",
        "      <span id=\"maxLen\"></span>\n",
        "    </div>\n",
        "  </div>\n",
        "  <hr>\n",
        "  <div>\n",
        "    <select id=\"example-select\" class=\"form-control\">\n",
        "      <option value=\"example1\">Alice's Adventures in Wonderland</option>\n",
        "      <option value=\"example2\">Dracula</option>\n",
        "      <option value=\"example3\">The Iliad</option>\n",
        "    </select>\n",
        "  </div>\n",
        "  <div>\n",
        "    <textarea id=\"text-entry\"></textarea>\n",
        "  </div>\n",
        "  <hr>\n",
        "  <div>\n",
        "    <span id=\"status\">Standing by.</span>\n",
        "  </div>\n",
        "\n",
        "  <script src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js'></script>\n",
        "  <script src='index.js'></script>\n",
        "</body>\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-JsQLbLnkhhk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index_js = \"\"\"\n",
        "const HOSTED_URLS = {\n",
        "  model:\n",
        "      'model_js/model.json',\n",
        "  metadata:\n",
        "      'model_js/metadata.json'\n",
        "};\n",
        "\n",
        "const examples = {\n",
        "  'example1':\n",
        "      'Alice was beginning to get very tired of sitting by her sister on the bank.',\n",
        "  'example2':\n",
        "      'Buda-Pesth seems a wonderful place.',\n",
        "  'example3':\n",
        "      'Scepticism was as much the result of knowledge, as knowledge is of scepticism.'      \n",
        "};\n",
        "\n",
        "function status(statusText) {\n",
        "  console.log(statusText);\n",
        "  document.getElementById('status').textContent = statusText;\n",
        "}\n",
        "\n",
        "function showMetadata(metadataJSON) {\n",
        "  document.getElementById('vocabularySize').textContent =\n",
        "      metadataJSON['vocabulary_size'];\n",
        "  document.getElementById('maxLen').textContent =\n",
        "      metadataJSON['max_len'];\n",
        "}\n",
        "\n",
        "function settextField(text, predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  textField.value = text;\n",
        "  doPredict(predict);\n",
        "}\n",
        "\n",
        "function setPredictFunction(predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  textField.addEventListener('input', () => doPredict(predict));\n",
        "}\n",
        "\n",
        "function disableLoadModelButtons() {\n",
        "  document.getElementById('load-model').style.display = 'none';\n",
        "}\n",
        "\n",
        "function doPredict(predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  const result = predict(textField.value);\n",
        "  score_string = \"Class scores: \";\n",
        "  for (var x in result.score) {\n",
        "    score_string += x + \" ->  \" + result.score[x].toFixed(3) + \", \"\n",
        "  }\n",
        "  //console.log(score_string);\n",
        "  status(\n",
        "      score_string + ' elapsed: ' + result.elapsed.toFixed(3) + ' ms)');\n",
        "}\n",
        "\n",
        "function prepUI(predict) {\n",
        "  setPredictFunction(predict);\n",
        "  const testExampleSelect = document.getElementById('example-select');\n",
        "  testExampleSelect.addEventListener('change', () => {\n",
        "    settextField(examples[testExampleSelect.value], predict);\n",
        "  });\n",
        "  settextField(examples['example1'], predict);\n",
        "}\n",
        "\n",
        "async function urlExists(url) {\n",
        "  status('Testing url ' + url);\n",
        "  try {\n",
        "    const response = await fetch(url, {method: 'HEAD'});\n",
        "    return response.ok;\n",
        "  } catch (err) {\n",
        "    return false;\n",
        "  }\n",
        "}\n",
        "\n",
        "async function loadHostedPretrainedModel(url) {\n",
        "  status('Loading pretrained model from ' + url);\n",
        "  try {\n",
        "    const model = await tf.loadLayersModel(url);\n",
        "    status('Done loading pretrained model.');\n",
        "    disableLoadModelButtons();\n",
        "    return model;\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    status('Loading pretrained model failed.');\n",
        "  }\n",
        "}\n",
        "\n",
        "async function loadHostedMetadata(url) {\n",
        "  status('Loading metadata from ' + url);\n",
        "  try {\n",
        "    const metadataJson = await fetch(url);\n",
        "    const metadata = await metadataJson.json();\n",
        "    status('Done loading metadata.');\n",
        "    return metadata;\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    status('Loading metadata failed.');\n",
        "  }\n",
        "}\n",
        "\n",
        "class Classifier {\n",
        "\n",
        "  async init(urls) {\n",
        "    this.urls = urls;\n",
        "    this.model = await loadHostedPretrainedModel(urls.model);\n",
        "    await this.loadMetadata();\n",
        "    return this;\n",
        "  }\n",
        "\n",
        "  async loadMetadata() {\n",
        "    const metadata =\n",
        "        await loadHostedMetadata(this.urls.metadata);\n",
        "    showMetadata(metadata);\n",
        "    this.maxLen = metadata['max_len'];\n",
        "    console.log('maxLen = ' + this.maxLen);\n",
        "    this.wordIndex = metadata['word_index']\n",
        "  }\n",
        "\n",
        "  predict(text) {\n",
        "    // Convert to lower case and remove all punctuations.\n",
        "    const inputText =\n",
        "        text.trim().toLowerCase().replace(/(\\.|\\,|\\!)/g, '').split(' ');\n",
        "    // Look up word indices.\n",
        "    const inputBuffer = tf.buffer([1, this.maxLen], 'float32');\n",
        "    for (let i = 0; i < inputText.length; ++i) {\n",
        "      const word = inputText[i];\n",
        "      inputBuffer.set(this.wordIndex[word], 0, i);\n",
        "      //console.log(word, this.wordIndex[word], inputBuffer);\n",
        "    }\n",
        "    const input = inputBuffer.toTensor();\n",
        "    //console.log(input);\n",
        "\n",
        "    status('Running inference');\n",
        "    const beginMs = performance.now();\n",
        "    const predictOut = this.model.predict(input);\n",
        "    //console.log(predictOut.dataSync());\n",
        "    const score = predictOut.dataSync();//[0];\n",
        "    predictOut.dispose();\n",
        "    const endMs = performance.now();\n",
        "\n",
        "    return {score: score, elapsed: (endMs - beginMs)};\n",
        "  }\n",
        "};\n",
        "\n",
        "async function setup() {\n",
        "  if (await urlExists(HOSTED_URLS.model)) {\n",
        "    status('Model available: ' + HOSTED_URLS.model);\n",
        "    const button = document.getElementById('load-model');\n",
        "    button.addEventListener('click', async () => {\n",
        "      const predictor = await new Classifier().init(HOSTED_URLS);\n",
        "      prepUI(x => predictor.predict(x));\n",
        "    });\n",
        "    button.style.display = 'inline-block';\n",
        "  }\n",
        "\n",
        "  status('Standing by.');\n",
        "}\n",
        "\n",
        "setup();\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbvVVh1rkmga",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('index.html','w') as f:\n",
        "  f.write(index_html)\n",
        "  \n",
        "with open('index.js','w') as f:\n",
        "  f.write(index_js)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0YtvaoazkuRT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z3NX9FVLiBO7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Commit and push everything. Note: we're storing binary files in GitHub, this isn't ideal (if you want to deploy a model down the road, better to host it in a cloud storage bucket)."
      ]
    },
    {
      "metadata": {
        "id": "RoL5aoRUh5DB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git add . \n",
        "!git commit -m \"colab -> github\"\n",
        "!git push https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io/ master"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1V1QLCxlikOI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Now, visit https://%s.github.io/%s/\" % (USER_NAME, SITE_NAME))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WDoo_fDVic2E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All done! Hopefully everything worked. You may need to wait a few moments for the changes to appear in your GitHub Pages site. If it's not working, check the JavaScript console for error messages (in Chrome: View -> Developer -> JavaScript Console).\n",
        "\n",
        "Note: if you are debugging and Chrome is failing to pick up your changes, though you've verified they're present in your GitHub repo, see the second answer to: https://superuser.com/questions/89809/how-to-force-refresh-without-cache-in-google-chrome"
      ]
    }
  ]
}