{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "a3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysjbluemoon/Applied-Deep-Learning/blob/master/Assignment%203/a3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWOHRLs9LRPI",
        "colab_type": "text"
      },
      "source": [
        "# A3: TensorBoard\n",
        "\n",
        "## About\n",
        "\n",
        "In this assignment, you will design and run experiments to evaluate the impact of a few common parameters (like the choice of activation function, optimizer, and weight initialization strategy) and visualize the results in TensorBoard.\n",
        "\n",
        "The starter code below shows the mechanics of using TensorBoard in Colab. Unlike the previous assignments, a limited amount of starter code is provided.  3c is an extra credit question, it's optional (you can receive full credit on this assignment without submitting it).\n",
        "\n",
        "## Questions\n",
        "\n",
        "### 3a. \n",
        "**Implement ReLU and compare against a previous activation function**.\n",
        "\n",
        "The year is 2010. It is not commonly known that ReLU is a useful alternative to activation functions like Sigmoid or Tanh (nor has ReLU been implemented in the library you're using). Create a DNN to classify MNIST, and provide your own implementation of ReLU (instead of using a built-in method). Design and run an experiment to compare ReLU against other methods, and use TensorBoard to display your results. What differences do you observe, and why?\n",
        "\n",
        "### 3b. \n",
        "\n",
        "**Optimizer and initalizer and soup**.\n",
        "\n",
        "Do optimizers like Momentum or Adam really make a difference? How about different weight initialize strategies (like random normal, or glorot uniform?) Design and run experiments to find out, and use TensorBoard to display your results. What differences do you observe, and why?\n",
        "\n",
        "### 3c. Extra credit (optional)\n",
        "\n",
        "**Demonstrate the vanishing gradient problem**. \n",
        "\n",
        "Implement an especially deep neural network and train it on a simple dataset like MNIST. Choose activation functions, initialization strategies, and an optimizer that are likely to cause this behavior. Produce histograms of activations and gradients at various layers during training. What do you see? Next, adjust the parameters above to correct this behavior. Visualize and compare the results.\n",
        "\n",
        "## Submission instructions\n",
        "\n",
        "Please submit your assignment on CourseWorks by uploading a zip file that includes:\n",
        "\n",
        "* A Jupyter notebook, containing complete code to reproduce your experiments, and saved output showing your results.\n",
        "\n",
        "* A README file (plaintext is fine). This should contain your written conclusions for each question. These can be brief (a couple paragraphs). Try to be specific in your answers (if ReLU outperfoms sigmoid, try to answer why).\n",
        "\n",
        "* Plots / diagrams (.jpgs). Since it is not convenient to save TensorBoard diagrams directly in a Jupyter notebook, you can take screenshots of your plots and submit them along with your Jupyter notebook in a zip file on CourseWorks. Please name your diagrams appropriately, and refer to them names in your notebook.\n",
        "\n",
        "If you are working in Colab, you can prepare your notebook for submission by ensuring that runs end-to-end, then saving and downloading it:\n",
        "\n",
        "1. ```Runtime -> Restart and run all```\n",
        "1. ```File -> Save```\n",
        "1. ```File -> Download.ipynb```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSc6v5ws8wKS",
        "colab_type": "text"
      },
      "source": [
        "## Starter code for TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE5lIlzkEUAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpe_UINKKLDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4sUrkaeKQSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ehUDr72LLAJY"
      },
      "source": [
        "**Caution**. The following cell will clear the logs directory. If you're running this on your local machine, be careful executing it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScjIcVAJKkmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./tensorboard-logs/ # Clear any logs from previous runs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ6aWI_NLm6C",
        "colab_type": "text"
      },
      "source": [
        "Import a dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByT9RfkIK4kD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2_huYeq80tv",
        "colab_type": "text"
      },
      "source": [
        "## First style"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMLofsyiLthK",
        "colab_type": "text"
      },
      "source": [
        "Define a simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHBo5cgTLuis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='softmax'),\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oEDGbBRMI-_",
        "colab_type": "text"
      },
      "source": [
        "Create a logs directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggu_lZRnL6Uf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime \n",
        "import os\n",
        "date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "log_dir = os.path.join(\"./tensorboard-logs/\", date)\n",
        "print(\"Writing logs to\", log_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_icHggivMBXe",
        "colab_type": "text"
      },
      "source": [
        "### Run an experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyVj4vmLM0Yw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "model = create_model() \n",
        "opt = SGD(learning_rate=0.001, momentum=0.0, nesterov=False) \n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "exp_dir = os.path.join(log_dir, \"exp1\")\n",
        "\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=exp_dir)\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=1, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tb_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6-cL05DN9fR",
        "colab_type": "text"
      },
      "source": [
        "### Run a second experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XVPmrpeN_u7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model() \n",
        "opt = SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "exp_dir = os.path.join(log_dir, \"exp2\")\n",
        "\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=exp_dir)\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=10, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tb_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_pSh18ZOENe",
        "colab_type": "text"
      },
      "source": [
        "### Start TensorBoard and compare the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRkOYWn7OGGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir \"$log_dir\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPLDEq8MSQYH",
        "colab_type": "text"
      },
      "source": [
        "## Second style\n",
        "Using a Subclassed model and a GradientTape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vV0Hz2RV1C5",
        "colab_type": "text"
      },
      "source": [
        "Prepre the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX0umywbPeW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "train_ds = train_ds.shuffle(60000).batch(32)\n",
        "test_ds = test_ds.batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZgdwTLLwq1D",
        "colab_type": "text"
      },
      "source": [
        "Define a simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRaR1rtpUgDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.flatten = Flatten(input_shape=(28, 28))\n",
        "    self.d1 = Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.flatten(x)\n",
        "    return self.d1(x)\n",
        "\n",
        "model = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMFRp7CCTxmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7aIkldyT1S9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZzldV1BV3Rs",
        "colab_type": "text"
      },
      "source": [
        "Training and testing routines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcDHIccXUP_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images)\n",
        "    loss = loss_fn(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  predictions = model(images)\n",
        "  t_loss = loss_fn(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEUmM7G6V7ae",
        "colab_type": "text"
      },
      "source": [
        "Prepare log writers (previously, these were handled by the callback)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGrEExdWV84_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "log_dir = os.path.join(\"./tensorboard-logs/\", date)\n",
        "print(\"Writing logs to\", log_dir)\n",
        "\n",
        "train_writer = tf.summary.create_file_writer(os.path.join(log_dir, \"train\"))\n",
        "test_writer = tf.summary.create_file_writer(os.path.join(log_dir, \"test\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v-gMTCiwuBO",
        "colab_type": "text"
      },
      "source": [
        "Train and log summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rxTf4CyVKxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 2\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  \n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "    \n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "  print(template.format(epoch+1,\n",
        "                        train_loss.result(),\n",
        "                        train_accuracy.result()*100,\n",
        "                        test_loss.result(),\n",
        "                        test_accuracy.result()*100))\n",
        "  \n",
        "  with train_writer.as_default():\n",
        "    tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
        "    tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
        "\n",
        "    # ====\n",
        "    # Demo: show how to use histogram summaries\n",
        "    # Create and log some random data\n",
        "    # Useful if you're attemping the extra credit question\n",
        "    # ====\n",
        "    data = tf.random.normal((32, 100))\n",
        "    tf.summary.histogram('random', \n",
        "                         data,\n",
        "                         step=epoch, \n",
        "                         description='Your description')\n",
        "    \n",
        "  with test_writer.as_default():\n",
        "    tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
        "    tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
        "    \n",
        "  # Reset the metrics for the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrXOlQa5VWnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir \"$log_dir\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}